{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yidjZQn-gvoH"
      },
      "outputs": [],
      "source": [
        "# !pip install clean-text\n",
        "# !pip install datasets\n",
        "# !pip install allennlp\n",
        "# !pip install --upgrade huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ9JTe10ghdw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import math\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('hatexplain_data.pickle', 'rb') as file:\n",
        "    data = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "documents = data[\"documents\"]\n",
        "train_documents = data[\"train_documents\"]\n",
        "test_documents = data[\"test_documents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDSmRE3aghd1"
      },
      "outputs": [],
      "source": [
        "print(train_documents[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPxpZe8hghd0"
      },
      "source": [
        "<h4>ELMo</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xIAXW8Bghd0"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained ELMo model\n",
        "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json\"\n",
        "weights_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway_5.5B/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHWvYvQmqFLJ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHOSfHygghd1"
      },
      "outputs": [],
      "source": [
        "# Assuming you've already initialized your ELMo model\n",
        "elmo = Elmo(options_file, weights_file, num_output_representations=1, dropout=0).to(device)\n",
        "\n",
        "def batch_generator(docs, batch_size):\n",
        "    \"\"\"Yield batches of documents.\"\"\"\n",
        "    for i in range(0, len(docs), batch_size):\n",
        "        yield docs[i:i+batch_size]\n",
        "\n",
        "def get_document_embeddings(documents, batch_size):\n",
        "    \"\"\"Generate document-level embeddings for the given documents, with a progress bar.\"\"\"\n",
        "    document_embeddings = []\n",
        "    # Wrap the batch generator with tqdm to display the progress\n",
        "    for batch in tqdm(batch_generator(documents, batch_size), total=math.ceil(len(documents) / batch_size)):\n",
        "        # Convert sentences to character ids\n",
        "        character_ids = batch_to_ids(batch).to(device)\n",
        "        embeddings = elmo(character_ids)\n",
        "\n",
        "        # Aggregate word embeddings to get document embeddings\n",
        "        # Here, we take the mean across the sequence length dimension\n",
        "        doc_embeddings = embeddings['elmo_representations'][0].mean(dim=1)\n",
        "        document_embeddings.extend(doc_embeddings.detach().cpu().numpy())\n",
        "\n",
        "    return np.array(document_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQFA8cmZghd1"
      },
      "source": [
        "<h4>ELMo Embeddings</h4>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qh0e9HSvI3W"
      },
      "outputs": [],
      "source": [
        "#Word2Vec Embeddings\n",
        "X_train_elmo = get_document_embeddings(train_documents, batch_size=50)\n",
        "X_test_elmo = get_document_embeddings(test_documents, batch_size=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-LzQKwG3y4k"
      },
      "outputs": [],
      "source": [
        "print(X_train_elmo.shape)\n",
        "print(X_train_elmo[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Cf80mOQCpxd"
      },
      "outputs": [],
      "source": [
        "print(X_train_elmo[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DUBgvAOwz9c"
      },
      "outputs": [],
      "source": [
        "data_to_save = {\n",
        "    \"X_train_elmo\": X_train_elmo,\n",
        "    \"X_test_elmo\": X_test_elmo\n",
        "}\n",
        "\n",
        "with open('elmo_embeddings.pickle', 'wb') as file:\n",
        "    pickle.dump(data_to_save, file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
