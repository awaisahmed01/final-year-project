{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleantext import clean\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(lst):\n",
    "    counts = Counter(lst)\n",
    "    return counts.most_common(1)[0][0]\n",
    "\n",
    "def format_hatexplain(dataset):\n",
    "    df = pd.concat([dataset[\"train\"].to_pandas(), dataset[\"validation\"].to_pandas(), dataset[\"test\"].to_pandas()])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = df.rename(columns={'post_tokens': 'unprocessed_docs'})\n",
    "    \n",
    "    df['labels'] = df['annotators'].apply(lambda x: x.get('label'))\n",
    "    df['final_label'] = df['labels'].apply(most_common)\n",
    "    df.drop('annotators', axis=1, inplace=True)\n",
    "    df.drop('rationales', axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Format Hatexplain</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"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\"\n",
    "hatexplain = load_dataset(\"hatexplain\", token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hatexplain = format_hatexplain(hatexplain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Preprocess Hatexplain Dataset</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(tokens, contractions):\n",
    "    # Function to replace a single token if it's a contraction\n",
    "    def replace_and_split_token(token):\n",
    "        # Check both original and lowercased token to ensure coverage\n",
    "        expanded_token = contractions.get(token, contractions.get(token.lower(), token))\n",
    "        return expanded_token.split()\n",
    "\n",
    "    expanded_tokens = [replace_and_split_token(token) for token in tokens]\n",
    "    return [item for sublist in expanded_tokens for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('contractions_dict.json', 'r', encoding='utf-8') as file:\n",
    "    contractions_dict = json.load(file)\n",
    "\n",
    "df_hatexplain['expanded_contractions'] = df_hatexplain['unprocessed_docs'].apply(lambda x: expand_contractions(x, contractions_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = ' '.join(text)\n",
    "    text = clean(text, no_emoji=True)\n",
    "    tokens = text.split(' ') \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the function to the DataFrame column\n",
    "df_hatexplain['documents'] = df_hatexplain['expanded_contractions'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hatexplain.drop('unprocessed_docs', axis=1, inplace=True)\n",
    "df_hatexplain.drop('expanded_contractions', axis=1, inplace=True)\n",
    "df_hatexplain = df_hatexplain[['id', 'documents', 'labels', 'final_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_hatexplain[\"expanded_contractions\"][10148])\n",
    "# df_hatexplain[\"preprocessed_docs\"][10148]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df_hatexplain[\"documents\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'really', 'think', 'i', 'would', 'not', 'have', 'been', 'raped', 'by', 'feral', 'hindu', 'or', 'muslim', 'back', 'in', 'india', 'or', 'bangladesh', 'and', 'a', 'neo', 'nazi', 'would', 'rape', 'me', 'as', 'well', 'just', 'to', 'see', 'me', 'cry']\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Data splitting</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Label Distribution:\n",
      "final_label\n",
      "1    6251\n",
      "0    4748\n",
      "2    4384\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Set Label Distribution:\n",
      "final_label\n",
      "1    1563\n",
      "0    1187\n",
      "2    1096\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use train_test_split to create a stratified split\n",
    "df_hatexplain_train, df_hatexplain_test = train_test_split(df_hatexplain, test_size=0.2, stratify=df_hatexplain['final_label'], random_state=42, shuffle=True)\n",
    "train_documents = df_hatexplain_train['documents'].tolist()\n",
    "test_documents = df_hatexplain_test['documents'].tolist()\n",
    "\n",
    "# Check the distribution of labels in each set\n",
    "\n",
    "train_distribution = df_hatexplain_train['final_label'].value_counts()\n",
    "test_distribution = df_hatexplain_test['final_label'].value_counts()\n",
    "print(\"\\nTraining Set Label Distribution:\")\n",
    "print(train_distribution)\n",
    "print(\"\\nTest Set Label Distribution:\")\n",
    "print(test_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_hatexplain_train['final_label'].values\n",
    "y_test = df_hatexplain_test['final_label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Binary Data Creation and Splitting</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5935\n",
      "5480\n",
      "7814\n"
     ]
    }
   ],
   "source": [
    "hate_df = df_hatexplain[df_hatexplain['final_label'] == 0]\n",
    "offensive_df = df_hatexplain[df_hatexplain['final_label'] == 2]\n",
    "normal_df = df_hatexplain[df_hatexplain['final_label'] == 1]\n",
    "\n",
    "num_samples_offensive = int(len(hate_df) * (len(offensive_df) / (len(offensive_df) + len(normal_df))))\n",
    "num_samples_normal = len(hate_df) - num_samples_offensive  \n",
    "\n",
    "offensive_sampled = offensive_df.sample(n=num_samples_offensive, random_state=42) \n",
    "normal_sampled = normal_df.sample(n=num_samples_normal, random_state=42)\n",
    "\n",
    "df_hatexplain_binary = pd.concat([hate_df, offensive_sampled, normal_sampled])\n",
    "df_hatexplain_binary['final_binary_label'] = df_hatexplain_binary['final_label'].apply(lambda x: 1 if (x == 1 or x == 2) else 0)\n",
    "df_hatexplain_binary = df_hatexplain_binary.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_binary = df_hatexplain_binary[\"documents\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Label Distribution:\n",
      "final_binary_label\n",
      "1    5342\n",
      "0    5341\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Set Label Distribution:\n",
      "final_binary_label\n",
      "0    594\n",
      "1    593\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use train_test_split to create a stratified split\n",
    "df_hatexplain_binary_train, df_hatexplain_binary_test = train_test_split(df_hatexplain_binary, test_size=0.10, stratify=df_hatexplain_binary['final_binary_label'], random_state=42, shuffle=True)\n",
    "train_documents_binary = df_hatexplain_binary_train['documents'].tolist()\n",
    "test_documents_binary = df_hatexplain_binary_test['documents'].tolist()\n",
    "\n",
    "# Check the distribution of labels in each set\n",
    "\n",
    "train_distribution_binary = df_hatexplain_binary_train['final_binary_label'].value_counts()\n",
    "test_distribution_binary = df_hatexplain_binary_test['final_binary_label'].value_counts()\n",
    "print(\"\\nTraining Set Label Distribution:\")\n",
    "print(train_distribution_binary)\n",
    "print(\"\\nTest Set Label Distribution:\")\n",
    "print(test_distribution_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = df_hatexplain_binary_train['final_binary_label'].values\n",
    "y_test_binary = df_hatexplain_binary_test['final_binary_label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'we', 'needed', 'were', '<number>', 'minute', 'videos', 'playing', '<number>', '<number>', 'in', '<number>', 'television', 'warning', 'us', 'about', 'the', 'evil', 'hart', 'celler', 'kike', 'change', 'the', 'people', 'immigration', 'scheme']\n",
      "['oprah', 'is', 'a', 'stupid', 'nigger', 'that', 'only', 'got', 'into', 'the', 'entertainment', 'business', 'because', 'she', 'fucked', 'a', 'kike', 'with', 'jungle', 'fever']\n"
     ]
    }
   ],
   "source": [
    "print(train_documents[0])\n",
    "print(train_documents_binary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data: a mix of numpy arrays and lists\n",
    "data_to_save = {\n",
    "    \"documents\": documents,\n",
    "    \"train_documents\": train_documents,\n",
    "    \"test_documents\": test_documents,\n",
    "    \"y_train\":y_train,\n",
    "    \"y_test\":y_test,\n",
    "    \"documents_binary\": documents_binary,\n",
    "    \"train_documents_binary\": train_documents_binary,\n",
    "    \"test_documents_binary\": test_documents_binary,\n",
    "    \"y_train_binary\":y_train_binary,\n",
    "    \"y_test_binary\":y_test_binary,\n",
    "}\n",
    "\n",
    "# To save a list or array\n",
    "with open('hatexplain_data.pickle', 'wb') as file:\n",
    "    pickle.dump(data_to_save, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
